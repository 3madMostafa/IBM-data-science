{"cells":[{"cell_type":"markdown","id":"d635514d-3cf2-449a-aea8-5e4fa9a207ba","metadata":{},"source":["\n","<h1 align=\"center\"><font size=\"5\">Final Project: Classification with Python</font></h1>\n"]},{"cell_type":"markdown","id":"ba96d793-1aa1-4070-b541-9cccd07b073f","metadata":{},"source":["<h2>Table of Contents</h2>\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ul>\n","    <li><a href=\"https://#Section_1\">Instructions</a></li>\n","    <li><a href=\"https://#Section_2\">About the Data</a></li>\n","    <li><a href=\"https://#Section_3\">Importing Data </a></li>\n","    <li><a href=\"https://#Section_4\">Data Preprocessing</a> </li>\n","    <li><a href=\"https://#Section_5\">One Hot Encoding </a></li>\n","    <li><a href=\"https://#Section_6\">Train and Test Data Split </a></li>\n","    <li><a href=\"https://#Section_7\">Train Logistic Regression, KNN, Decision Tree, SVM, and Linear Regression models and return their appropriate accuracy scores</a></li>\n","</a></li>\n","</div>\n","<p>Estimated Time Needed: <strong>180 min</strong></p>\n","</div>\n","\n","<hr>\n"]},{"cell_type":"markdown","id":"62e2bfb2-08bd-41de-a704-c72028242793","metadata":{},"source":["# Instructions\n"]},{"cell_type":"markdown","id":"c06281fa-8a02-493f-9b69-4b6738e6c8eb","metadata":{},"source":["In this notebook, you will  practice all the classification algorithms that we have learned in this course.\n","\n","\n","Below, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n","\n","We will use some of the algorithms taught in the course, specifically:\n","\n","1. Linear Regression\n","2. KNN\n","3. Decision Trees\n","4. Logistic Regression\n","5. SVM\n","\n","We will evaluate our models using:\n","\n","1.  Accuracy Score\n","2.  Jaccard Index\n","3.  F1-Score\n","4.  LogLoss\n","5.  Mean Absolute Error\n","6.  Mean Squared Error\n","7.  R2-Score\n","\n","Finally, you will use your models to generate the report at the end. \n"]},{"cell_type":"markdown","id":"9d4ee051-f50c-4ce5-aba1-167ffc8f5648","metadata":{},"source":["# About The Dataset\n"]},{"cell_type":"markdown","id":"4e4d2b57-e9af-4a7d-a7f9-b8c25660ba78","metadata":{},"source":["The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n","\n","The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n","\n"]},{"cell_type":"markdown","id":"4b2d517d-9973-438d-8d32-dff28ad6ce84","metadata":{},"source":["This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n","\n","| Field         | Description                                           | Unit            | Type   |\n","| ------------- | ----------------------------------------------------- | --------------- | ------ |\n","| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n","| Location      | Location of the Observation                           | Location        | object |\n","| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n","| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n","| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n","| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n","| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n","| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n","| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n","| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n","| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n","| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n","| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n","| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n","| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n","| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n","| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n","| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n","| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n","| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n","| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n","| RainToday     | If there was rain today                               | Yes/No          | object |\n","| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n","\n","Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n"]},{"cell_type":"markdown","id":"3ad995f0-a174-49a5-aaef-76294021d5d4","metadata":{},"source":["## **Import the required libraries**\n"]},{"cell_type":"code","execution_count":3,"id":"38dca360-78ed-407c-9f48-26b405bf8695","metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"code","execution_count":4,"id":"ece29267-503d-4de0-8c69-f905815d57a3","metadata":{},"outputs":[],"source":["# Surpress warnings:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":5,"id":"2344f678-d444-4a13-bd7f-d730f954116f","metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import svm\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import sklearn.metrics as metrics\n","from sklearn.metrics import jaccard_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import log_loss\n","from sklearn.metrics import confusion_matrix, accuracy_score"]},{"cell_type":"markdown","id":"2bdad242-edb6-4a5b-8471-f5918f3ecab7","metadata":{},"source":["### Importing the Dataset\n"]},{"cell_type":"code","execution_count":6,"id":"f9c77ad8-8b85-4e82-af47-f63163f889c3","metadata":{},"outputs":[],"source":["filepath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv\"\n","df = pd.read_csv(filepath)"]},{"cell_type":"code","execution_count":7,"id":"2fd31b01-a2bf-4263-8ff8-6fdce1990047","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>MinTemp</th>\n","      <th>MaxTemp</th>\n","      <th>Rainfall</th>\n","      <th>Evaporation</th>\n","      <th>Sunshine</th>\n","      <th>WindGustDir</th>\n","      <th>WindGustSpeed</th>\n","      <th>WindDir9am</th>\n","      <th>WindDir3pm</th>\n","      <th>...</th>\n","      <th>Humidity9am</th>\n","      <th>Humidity3pm</th>\n","      <th>Pressure9am</th>\n","      <th>Pressure3pm</th>\n","      <th>Cloud9am</th>\n","      <th>Cloud3pm</th>\n","      <th>Temp9am</th>\n","      <th>Temp3pm</th>\n","      <th>RainToday</th>\n","      <th>RainTomorrow</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/1/2008</td>\n","      <td>19.5</td>\n","      <td>22.4</td>\n","      <td>15.6</td>\n","      <td>6.2</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>S</td>\n","      <td>SSW</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>84</td>\n","      <td>1017.6</td>\n","      <td>1017.4</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>20.7</td>\n","      <td>20.9</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2/2/2008</td>\n","      <td>19.5</td>\n","      <td>25.6</td>\n","      <td>6.0</td>\n","      <td>3.4</td>\n","      <td>2.7</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>W</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>83</td>\n","      <td>73</td>\n","      <td>1017.9</td>\n","      <td>1016.4</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>22.4</td>\n","      <td>24.8</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2/3/2008</td>\n","      <td>21.6</td>\n","      <td>24.5</td>\n","      <td>6.6</td>\n","      <td>2.4</td>\n","      <td>0.1</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>ESE</td>\n","      <td>ESE</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>86</td>\n","      <td>1016.7</td>\n","      <td>1015.6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>23.5</td>\n","      <td>23.0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2/4/2008</td>\n","      <td>20.2</td>\n","      <td>22.8</td>\n","      <td>18.8</td>\n","      <td>2.2</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>NNE</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>83</td>\n","      <td>90</td>\n","      <td>1014.2</td>\n","      <td>1011.8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>21.4</td>\n","      <td>20.9</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2/5/2008</td>\n","      <td>19.7</td>\n","      <td>25.7</td>\n","      <td>77.4</td>\n","      <td>4.8</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>NNE</td>\n","      <td>W</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>74</td>\n","      <td>1008.3</td>\n","      <td>1004.8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>22.5</td>\n","      <td>25.5</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n","0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n","1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n","2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n","3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n","4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n","\n","   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n","0             41          S        SSW  ...           92           84   \n","1             41          W          E  ...           83           73   \n","2             41        ESE        ESE  ...           88           86   \n","3             41        NNE          E  ...           83           90   \n","4             41        NNE          W  ...           88           74   \n","\n","   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n","0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n","1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n","2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n","3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n","4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n","\n","   RainTomorrow  \n","0           Yes  \n","1           Yes  \n","2           Yes  \n","3           Yes  \n","4           Yes  \n","\n","[5 rows x 22 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","id":"eb2f4134-ab8b-48d8-aaab-85ce530aee65","metadata":{},"source":["### Data Preprocessing\n"]},{"cell_type":"markdown","id":"c70975f9-cae8-4cc6-be94-dbc1a880d3c9","metadata":{},"source":["#### One Hot Encoding\n"]},{"cell_type":"markdown","id":"cfadd018-a23d-4985-9eb3-8ed0d30abd52","metadata":{},"source":["First, we need to perform one hot encoding to convert categorical variables to binary variables.\n"]},{"cell_type":"code","execution_count":8,"id":"55968fd3-0422-4766-98fd-9397e0006e3e","metadata":{},"outputs":[],"source":["df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"]},{"cell_type":"markdown","id":"e354a6fc-8c8b-499d-8444-5011a5146b1a","metadata":{},"source":["Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"]},{"cell_type":"code","execution_count":9,"id":"77f75277-a3ca-4ccc-a5b7-f95b2491cc9b","metadata":{},"outputs":[],"source":["df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"]},{"cell_type":"markdown","id":"88ab6c18-f36a-408c-8510-fdf831abc53b","metadata":{},"source":["### Training Data and Test Data\n"]},{"cell_type":"markdown","id":"2a25156c-4080-4b15-a45c-9d4884ddce06","metadata":{},"source":["Now, we set our 'features' or x values and our Y or target variable.\n"]},{"cell_type":"code","execution_count":10,"id":"3077604d-a2f3-4e24-88ff-64b5ce69d6f0","metadata":{},"outputs":[],"source":["df_sydney_processed.drop('Date',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":11,"id":"e1b66dd7-5bb7-4739-96b8-374d8e89269e","metadata":{},"outputs":[],"source":["df_sydney_processed = df_sydney_processed.astype(float)"]},{"cell_type":"code","execution_count":12,"id":"29857426-177a-4c87-8982-4fdca4ff4d78","metadata":{},"outputs":[],"source":["features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n","Y = df_sydney_processed['RainTomorrow']"]},{"cell_type":"markdown","id":"1be81f61-64c3-43d0-89a8-22ff1a9339cf","metadata":{},"source":["### Linear Regression\n"]},{"cell_type":"markdown","id":"60256d7f-4d49-4aed-b2df-dc44a5b0791c","metadata":{},"source":["#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"]},{"cell_type":"code","execution_count":13,"id":"843e32d6-7bdd-4d12-b10a-de70bed0e974","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":14,"id":"c38f2196-bb38-4322-a012-9a27e6a9d8d8","metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=10)"]},{"cell_type":"markdown","id":"b144e3a9-6bd2-4e75-8cae-50e1e3b3fb17","metadata":{},"source":["#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":17,"id":"22b77c93-ecf2-4c54-8ad4-496ef5396695","metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n"]},{"cell_type":"markdown","id":"1aa0f086-fefc-4e44-8aa2-822aa7828ad6","metadata":{},"source":["#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"id":"a63dfa3d-a957-48dc-a067-93e9b3d11431","metadata":{},"outputs":[],"source":["x_test = np.array([[6], [7]])"]},{"cell_type":"code","execution_count":null,"id":"d6bdf734-7705-4590-aa54-6b93e20a9da7","metadata":{},"outputs":[],"source":["predictions = LinearReg.predict(x_test)\n","print(predictions)"]},{"cell_type":"markdown","id":"ea13e307-0ac9-4c7c-874e-440cee795d95","metadata":{},"source":["#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":20,"id":"cf2408d4-4932-487d-85f2-913c2efce09f","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"X has 1 features, but LinearRegression is expecting 66 features as input.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mLinearReg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: X has 1 features, but LinearRegression is expecting 66 features as input."]}],"source":[]},{"cell_type":"code","execution_count":null,"id":"aba34a58-a974-467b-8bad-10a0fd0e88d3","metadata":{},"outputs":[],"source":["LinearRegression_MAE = \n","LinearRegression_MSE = \n","LinearRegression_R2 = "]},{"cell_type":"markdown","id":"4552ab70-ec8a-4455-8c5f-f75f6e2e2771","metadata":{},"source":["#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"]},{"cell_type":"code","execution_count":null,"id":"cc932bbd-9528-45b5-b85a-8c9a0b9560ed","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"edd964f0-d1aa-4e3b-9a52-577656477438","metadata":{},"outputs":[],"source":["Report = "]},{"cell_type":"markdown","id":"55351393-abee-4af8-8944-f0079265cd56","metadata":{},"source":["### KNN\n"]},{"cell_type":"markdown","id":"b7e38ebb-7442-4980-b883-e89c6de0d351","metadata":{},"source":["#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"]},{"cell_type":"code","execution_count":null,"id":"213be9cb-8c88-4099-b023-def7c0e31c6a","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"f03fe0e5-ac9f-42cd-a107-d5d46b16ae4d","metadata":{},"outputs":[],"source":["KNN = "]},{"cell_type":"markdown","id":"0ef93a31-0d67-4fa5-809b-a765b13f5888","metadata":{},"source":["#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"id":"cf386d08-521b-418b-a5d6-601318bd8e93","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"8f88815e-92fd-4920-983c-326502b8bc29","metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","id":"9913f102-99a8-4af3-858d-1a55a2d49259","metadata":{},"source":["#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"id":"02eb3dd1-0c03-407a-9042-d446bd5ce557","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"47ddb040-001c-4c7f-907a-e0fe69d2bfb7","metadata":{},"outputs":[],"source":["KNN_Accuracy_Score = \n","KNN_JaccardIndex = \n","KNN_F1_Score = "]},{"cell_type":"markdown","id":"b1b49d21-0f4b-4737-a15c-88574afb6dc5","metadata":{},"source":["### Decision Tree\n"]},{"cell_type":"markdown","id":"07aedd58-1090-48ed-8fe9-38c64f4492ad","metadata":{},"source":["#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":null,"id":"b61b238f-7880-4cd9-9764-b69b5c63f352","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"f4a9ea81-7336-4cab-aa98-22cb6c6e79ca","metadata":{},"outputs":[],"source":["Tree = "]},{"cell_type":"markdown","id":"d79279ba-1e22-45c9-a6a7-e1a39a61c512","metadata":{},"source":["#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"id":"5c99f9a8-2fa2-48f3-83e9-8781dc1b0d61","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"4f6ea989-4778-47c8-9bc0-f6fae679f3c3","metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","id":"f19bae36-1072-4baf-bcf8-3c098eeb1915","metadata":{},"source":["#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"id":"0c47c2e2-14c7-4e5a-aaea-86212a0fa032","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"edb09a5f-c3e2-4c4f-924b-85f6ffe96729","metadata":{},"outputs":[],"source":["Tree_Accuracy_Score = \n","Tree_JaccardIndex = \n","Tree_F1_Score = "]},{"cell_type":"markdown","id":"f2905933-3b27-4ece-a80a-b35744f54b5f","metadata":{},"source":["### Logistic Regression\n"]},{"cell_type":"markdown","id":"490cdcfd-14aa-417d-b3ed-29577d13f7da","metadata":{},"source":["#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"]},{"cell_type":"code","execution_count":null,"id":"31bb6aa1-c399-4aed-89eb-4800b1854f0f","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"f7f13536-93e4-4edd-9c75-49a6d342f446","metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = "]},{"cell_type":"markdown","id":"cd2f53d8-3983-4581-8363-f11950b80b85","metadata":{},"source":["#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"]},{"cell_type":"code","execution_count":null,"id":"d8bf2bf5-8c9b-4250-beca-591e1a62dd1d","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"57ef08e5-9b64-4337-92a6-9af7f98a81a4","metadata":{},"outputs":[],"source":["LR = "]},{"cell_type":"markdown","id":"cdaf1cdd-61de-46e4-a252-6641aa13998b","metadata":{},"source":["#### Q14) Now, use the `predict` and `predict_proba` methods on the testing data (`x_test`) and save it as 2 arrays `predictions` and `predict_proba`.\n"]},{"cell_type":"code","execution_count":null,"id":"421725a3-8a77-4239-b6ee-3f7053ad6807","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"b2aad2f1-d2b7-4267-ab2e-1913d6b681a8","metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"code","execution_count":null,"id":"855f934b-4098-4e23-b5dd-b1ebff6c02b8","metadata":{},"outputs":[],"source":["predict_proba = "]},{"cell_type":"markdown","id":"08f3dc13-8be2-4d1e-9866-ff97141ae692","metadata":{},"source":["#### Q15) Using the `predictions`, `predict_proba` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"id":"0be54747-7fa3-46e6-a4cf-bd5e820ac616","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"6dc992b9-a3f8-49b5-a988-90118971013f","metadata":{},"outputs":[],"source":["LR_Accuracy_Score = \n","LR_JaccardIndex = \n","LR_F1_Score = \n","LR_Log_Loss = "]},{"cell_type":"markdown","id":"0c7326ae-5aa6-4666-b4d6-0705e5bcb771","metadata":{},"source":["### SVM\n"]},{"cell_type":"markdown","id":"920bae21-8886-4705-b6b1-85c1ca4506ee","metadata":{},"source":["#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":null,"id":"4ed2651e-3dd8-46bd-8a31-e7efa095a5dc","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"55d94ee3-60bb-4307-8fae-8d87dfd0f5ad","metadata":{},"outputs":[],"source":["SVM = "]},{"cell_type":"markdown","id":"755cb519-2721-4674-9d21-85a154fde994","metadata":{},"source":["#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"id":"de56e316-aaca-4ed9-89eb-1d69140ff04c","metadata":{},"outputs":[],"source":["#Enter Your Code and Execute"]},{"cell_type":"code","execution_count":null,"id":"cb98d313-75b6-4bea-b79c-efec4b9e412c","metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","id":"961ccca3-1fac-476a-93d2-39d6c8b3905b","metadata":{},"source":["#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"id":"34922618-6a7d-494c-a1b6-5f515f29a801","metadata":{},"outputs":[],"source":["SVM_Accuracy_Score = \n","SVM_JaccardIndex = \n","SVM_F1_Score = "]},{"cell_type":"markdown","id":"4e02f921-2696-4a0b-b9b6-cfc89a55f77d","metadata":{},"source":["### Report\n"]},{"cell_type":"markdown","id":"1f696bf7-a40a-404b-af35-b9a66f6304d6","metadata":{},"source":["#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n","\n","\\*LogLoss is only for Logistic Regression Model\n"]},{"cell_type":"code","execution_count":null,"id":"f7cc9f99-9da8-48e1-916e-fd642e28b773","metadata":{},"outputs":[],"source":["Report = "]},{"cell_type":"markdown","id":"d7463336-6b5d-4e9e-97a2-86fdf095a9f0","metadata":{},"source":["<h2 id=\"Section_5\">  How to submit </h2>\n","\n","<p>Once you complete your notebook you will have to share it. \n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"prev_pub_hash":"ba039b1c59dfa11e53b73e3fc8c403e1e8b43c7aedf6f7e0b1d1e7914b44d98a"},"nbformat":4,"nbformat_minor":4}
